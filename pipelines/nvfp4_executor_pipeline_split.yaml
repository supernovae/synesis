# PIPELINE DEFINITION
# Name: synesis-nvfp4-executor-split
# Description: Quantize 70B with NVFP4, copy to PVC, build ModelCar â€” avoids OOM
# Inputs:
#    dataset_id: str [Default: 'HuggingFaceH4/ultrachat_200k']
#    dataset_split: str [Default: 'train_sft']
#    ecr_uri: str [Default: '123456789012.dkr.ecr.us-east-1.amazonaws.com/synesis-models']
#    image_tag: str [Default: 'executor-nvfp4']
#    model_id: str [Default: 'deepseek-ai/DeepSeek-R1-Distill-Llama-70B']
#    pvc_name: str [Default: 'executor-build-pvc']
components:
  comp-build-and-push-modelcar:
    executorLabel: exec-build-and-push-modelcar
    inputDefinitions:
      parameters:
        ecr_uri:
          parameterType: STRING
        image_tag:
          parameterType: STRING
  comp-copy-artifact-to-pvc:
    executorLabel: exec-copy-artifact-to-pvc
    inputDefinitions:
      artifacts:
        input_model:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-run-nvfp4-calibrated:
    executorLabel: exec-run-nvfp4-calibrated
    inputDefinitions:
      parameters:
        dataset_id:
          parameterType: STRING
        dataset_split:
          parameterType: STRING
        max_sequence_length:
          defaultValue: 2048.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        model_id:
          parameterType: STRING
        num_calibration_samples:
          defaultValue: 128.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        recipe:
          parameterType: STRING
        seed:
          defaultValue: 42.0
          isOptional: true
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        output_model:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-build-and-push-modelcar:
      container:
        args:
        - /data/executor-model
        - '{{$.inputs.parameters[''ecr_uri'']}}'
        - '{{$.inputs.parameters[''image_tag'']}}'
        command:
        - /usr/local/bin/ecr-login-and-buildah.sh
        image: 660250927410.dkr.ecr.us-east-1.amazonaws.com/byron-ai-registry:buildah-ecr
        resources:
          cpuRequest: 2.0
          memoryLimit: 60.129542144
          memoryRequest: 8.589934592
          resourceCpuRequest: 2000m
          resourceMemoryLimit: 56Gi
          resourceMemoryRequest: 8Gi
    exec-copy-artifact-to-pvc:
      container:
        args:
        - mkdir -p /data/executor-model && cp -a $1/. /data/executor-model/
        - '{{$.inputs.artifacts[''input_model''].path}}'
        command:
        - sh
        - -c
        image: registry.access.redhat.com/ubi9/ubi-minimal:latest
        resources:
          cpuRequest: 1.0
          memoryLimit: 4.294967296
          memoryRequest: 2.147483648
          resourceCpuRequest: 1000m
          resourceMemoryLimit: 4Gi
          resourceMemoryRequest: 2Gi
    exec-run-nvfp4-calibrated:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - run_nvfp4_calibrated
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.16.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef run_nvfp4_calibrated(\n    model_id: str,\n    recipe: str,\n\
          \    dataset_id: str,\n    dataset_split: str,\n    output_model: dsl.Output[dsl.Artifact],\n\
          \    num_calibration_samples: int = 128,\n    max_sequence_length: int =\
          \ 2048,\n    seed: int = 42,\n):\n    \"\"\"Quantize model with NVFP4 (requires\
          \ calibration data).\"\"\"\n    from datasets import load_dataset\n    from\
          \ llmcompressor import oneshot\n    from transformers import AutoModelForCausalLM,\
          \ AutoTokenizer\n\n    ds = load_dataset(dataset_id, split=dataset_split)\n\
          \    ds = ds.shuffle(seed=seed).select(range(num_calibration_samples))\n\
          \n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n\n    def preprocess(example):\n\
          \        return {\n            \"text\": tokenizer.apply_chat_template(\n\
          \                example[\"messages\"],\n                tokenize=False,\n\
          \            )\n        }\n\n    ds = ds.map(preprocess)\n\n    def tokenize(sample):\n\
          \        return tokenizer(\n            sample[\"text\"],\n            padding=False,\n\
          \            max_length=max_sequence_length,\n            truncation=True,\n\
          \            add_special_tokens=False,\n        )\n\n    ds = ds.map(tokenize,\
          \ remove_columns=ds.column_names)\n\n    model = AutoModelForCausalLM.from_pretrained(\n\
          \        model_id, device_map=\"auto\", torch_dtype=\"auto\"\n    )\n  \
          \  tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n\
          \n    model = oneshot(\n        model=model,\n        dataset=ds,\n    \
          \    recipe=recipe,\n        tokenizer=tokenizer,\n        max_seq_length=max_sequence_length,\n\
          \        num_calibration_samples=num_calibration_samples,\n    )\n\n   \
          \ model.save_pretrained(output_model.path, save_compressed=True)\n    tokenizer.save_pretrained(output_model.path)\n\
          \    return\n\n"
        image: quay.io/opendatahub/llmcompressor-pipeline-runtime:main
        resources:
          accelerator:
            count: '1'
            resourceCount: '1'
            resourceType: nvidia.com/gpu
            type: nvidia.com/gpu
          cpuLimit: 8.0
          cpuRequest: 2.0
          memoryLimit: 80.0
          memoryRequest: 24.0
          resourceCpuLimit: 8000m
          resourceCpuRequest: 2000m
          resourceMemoryLimit: 80G
          resourceMemoryRequest: 24G
pipelineInfo:
  description: "Quantize 70B with NVFP4, copy to PVC, build ModelCar \u2014 avoids\
    \ OOM"
  name: synesis-nvfp4-executor-split
root:
  dag:
    tasks:
      build-and-push-modelcar:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-build-and-push-modelcar
        dependentTasks:
        - copy-artifact-to-pvc
        inputs:
          parameters:
            ecr_uri:
              componentInputParameter: ecr_uri
            image_tag:
              componentInputParameter: image_tag
        taskInfo:
          name: build-and-push-modelcar
      copy-artifact-to-pvc:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-copy-artifact-to-pvc
        dependentTasks:
        - run-nvfp4-calibrated
        inputs:
          artifacts:
            input_model:
              taskOutputArtifact:
                outputArtifactKey: output_model
                producerTask: run-nvfp4-calibrated
        taskInfo:
          name: copy-artifact-to-pvc
      run-nvfp4-calibrated:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-run-nvfp4-calibrated
        inputs:
          parameters:
            dataset_id:
              componentInputParameter: dataset_id
            dataset_split:
              componentInputParameter: dataset_split
            model_id:
              componentInputParameter: model_id
            recipe:
              runtimeValue:
                constant: "\nquant_stage:\n  quant_modifiers:\n    QuantizationModifier:\n\
                  \      ignore: [\"lm_head\"]\n      targets: [\"Linear\"]\n    \
                  \  scheme: \"NVFP4\"\n"
        taskInfo:
          name: run-nvfp4-calibrated
  inputDefinitions:
    parameters:
      dataset_id:
        defaultValue: HuggingFaceH4/ultrachat_200k
        isOptional: true
        parameterType: STRING
      dataset_split:
        defaultValue: train_sft
        isOptional: true
        parameterType: STRING
      ecr_uri:
        defaultValue: 123456789012.dkr.ecr.us-east-1.amazonaws.com/synesis-models
        isOptional: true
        parameterType: STRING
      image_tag:
        defaultValue: executor-nvfp4
        isOptional: true
        parameterType: STRING
      model_id:
        defaultValue: deepseek-ai/DeepSeek-R1-Distill-Llama-70B
        isOptional: true
        parameterType: STRING
      pvc_name:
        defaultValue: executor-build-pvc
        isOptional: true
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.16.0
---
platforms:
  kubernetes:
    deploymentSpec:
      executors:
        exec-build-and-push-modelcar:
          emptyDirMounts:
          - mountPath: /var/lib/containers
            volumeName: buildah-storage
          imagePullPolicy: Always
          pvcMount:
          - componentInputParameter: pvc_name
            mountPath: /data
            pvcNameParameter:
              componentInputParameter: pvc_name
          secretAsEnv:
          - keyToEnv:
            - envVar: AWS_ACCESS_KEY_ID
              secretKey: AWS_ACCESS_KEY_ID
            - envVar: AWS_SECRET_ACCESS_KEY
              secretKey: AWS_SECRET_ACCESS_KEY
            optional: false
            secretName: aws-ecr-credentials
            secretNameParameter:
              runtimeValue:
                constant: aws-ecr-credentials
          - keyToEnv:
            - envVar: AWS_SESSION_TOKEN
              secretKey: AWS_SESSION_TOKEN
            optional: true
            secretName: aws-ecr-session-token
            secretNameParameter:
              runtimeValue:
                constant: aws-ecr-session-token
        exec-copy-artifact-to-pvc:
          pvcMount:
          - componentInputParameter: pvc_name
            mountPath: /data
            pvcNameParameter:
              componentInputParameter: pvc_name
        exec-run-nvfp4-calibrated:
          secretAsEnv:
          - keyToEnv:
            - envVar: HF_TOKEN
              secretKey: HF_TOKEN
            optional: false
            secretName: hf-hub-secret
            secretNameParameter:
              runtimeValue:
                constant: hf-hub-secret
          tolerations:
          - effect: NoSchedule
            key: nvidia.com/gpu
            operator: Equal
            value: 'true'
